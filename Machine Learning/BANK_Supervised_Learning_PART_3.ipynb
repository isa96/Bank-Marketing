{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YL6LZ0GeXWTn"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#model processing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score, learning_curve, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score, log_loss, matthews_corrcoef\n",
    "\n",
    "#model deployment\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSMmmusaX9G5"
   },
   "source": [
    "Here I will just use logistic regression model in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "TFyt0XxyX6pX",
    "outputId": "c17acc8a-ee28-4537-f3fe-9addfb4569e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7413415d-d6cc-4165-8be9-d41e6e9887f4\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-7413415d-d6cc-4165-8be9-d41e6e9887f4\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving banksig.csv to banksig.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvNe5WAeYGP5"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "banksig = pd.read_csv(io.BytesIO(uploaded['banksig.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "kCeZFSBlYUMx",
    "outputId": "c6b7501c-9726-4f83-ef3c-f5852e1d9394"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-74e38766-4051-43ee-9910-2006d6c6630c\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-74e38766-4051-43ee-9910-2006d6c6630c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving bank-additional-full.csv to bank-additional-full.csv\n"
     ]
    }
   ],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGOLq7oWYWxA"
   },
   "outputs": [],
   "source": [
    "bank = pd.read_csv(io.BytesIO(uploaded['bank-additional-full.csv']), delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35PJwyRGYZHP"
   },
   "outputs": [],
   "source": [
    "target = bank['y'].apply(lambda x: 1 if x == 'yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uTyCdWdYkXH"
   },
   "source": [
    "According to our previous observation, I decided to use logistic model that has been tuned based on several hyperparameter. The F1 score and recall are better than without tuning. However, there is still room to improve. We can also use logistic analysis to describe the features -- to observe which one(s) is more likely to increase the likelihood to be in Target Yes, and which one(s) to decrease it. We can also see which features that the model considered as not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgYOPHfxZc4P"
   },
   "outputs": [],
   "source": [
    "# Initiate the model\n",
    "log_reg = LogisticRegression(solver = 'saga', penalty = 'l1', class_weight = 'balanced', max_iter = 1500, C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKydSIkeZp7T"
   },
   "outputs": [],
   "source": [
    "# Splitting the train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(banksig, target, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sn0YAYwZyU7"
   },
   "outputs": [],
   "source": [
    "# Scaling the X_train and transforming the X_test -- these are the ones we will use\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_trainscale = scaler.fit_transform(X_train)\n",
    "X_testscale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938
    },
    "colab_type": "code",
    "id": "CiMAeIteaCM3",
    "outputId": "aa0b16ed-31d7-4918-ef08-72f8d0008f36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2542: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284240\n",
      "         Iterations: 254\n",
      "         Function evaluations: 261\n",
      "         Gradient evaluations: 261\n",
      "                                    Results: Logit\n",
      "======================================================================================\n",
      "Model:                     Logit                   Pseudo R-squared:        0.195     \n",
      "Dependent Variable:        y                       AIC:                     16451.8402\n",
      "Date:                      2020-03-30 03:10        BIC:                     16708.1856\n",
      "No. Observations:          28831                   Log-Likelihood:          -8194.9   \n",
      "Df Model:                  30                      LL-Null:                 -10176.   \n",
      "Df Residuals:              28800                   LLR p-value:             0.0000    \n",
      "Converged:                 1.0000                  Scale:                   1.0000    \n",
      "--------------------------------------------------------------------------------------\n",
      "                             Coef.    Std.Err.     z     P>|z|     [0.025     0.975]  \n",
      "--------------------------------------------------------------------------------------\n",
      "const                       -45.4012 17595.3281  -0.0026 0.9979 -34531.6105 34440.8081\n",
      "job_admin.                    0.0266     0.0551   0.4830 0.6291     -0.0814     0.1347\n",
      "job_blue-collar              -0.1488     0.0751  -1.9821 0.0475     -0.2960    -0.0017\n",
      "job_entrepreneur             -0.0319     0.1250  -0.2549 0.7988     -0.2769     0.2131\n",
      "job_retired                   0.3437     0.1035   3.3213 0.0009      0.1409     0.5466\n",
      "job_services                 -0.2021     0.0872  -2.3171 0.0205     -0.3731    -0.0312\n",
      "job_student                   0.2830     0.1162   2.4345 0.0149      0.0552     0.5108\n",
      "job_unemployed                0.0294     0.1261   0.2333 0.8155     -0.2177     0.2765\n",
      "marital_married               0.0369     0.0689   0.5361 0.5919     -0.0981     0.1719\n",
      "marital_single                0.0791     0.0787   1.0049 0.3149     -0.0751     0.2333\n",
      "education_basic               0.0250     0.0629   0.3983 0.6904     -0.0982     0.1482\n",
      "education_university.degree   0.0671     0.0522   1.2842 0.1991     -0.0353     0.1694\n",
      "education_unknown             0.0404     0.1042   0.3880 0.6980     -0.1638     0.2447\n",
      "default_no                    8.8717   216.7132   0.0409 0.9673   -415.8783   433.6217\n",
      "default_unknown               8.5946   216.7132   0.0397 0.9684   -416.1554   433.3446\n",
      "contact_cellular            -22.4519 17596.6624  -0.0013 0.9990 -34511.2765 34466.3727\n",
      "contact_telephone           -22.9493 17596.6624  -0.0013 0.9990 -34511.7739 34465.8753\n",
      "month_apr                    -0.1028     0.0821  -1.2526 0.2103     -0.2637     0.0581\n",
      "month_dec                     0.4318     0.1855   2.3284 0.0199      0.0683     0.7953\n",
      "month_jul                     0.2350     0.0691   3.4006 0.0007      0.0996     0.3704\n",
      "month_mar                     1.0068     0.1274   7.9022 0.0000      0.7571     1.2565\n",
      "month_may                    -0.6966     0.0649 -10.7302 0.0000     -0.8238    -0.5694\n",
      "month_oct                     0.1187     0.1068   1.1121 0.2661     -0.0905     0.3279\n",
      "month_sep                    -0.2631     0.1159  -2.2707 0.0232     -0.4901    -0.0360\n",
      "day_of_week_mon              -0.2414     0.0543  -4.4416 0.0000     -0.3479    -0.1349\n",
      "day_of_week_thu              -0.0382     0.0522  -0.7323 0.4640     -0.1404     0.0640\n",
      "age                          -0.0004     0.0024  -0.1688 0.8660     -0.0052     0.0044\n",
      "campaign                     -0.0590     0.0114  -5.1825 0.0000     -0.0813    -0.0367\n",
      "previous                      0.1109     0.0330   3.3569 0.0008      0.0461     0.1756\n",
      "cons.price.idx                0.6554     0.0481  13.6207 0.0000      0.5611     0.7497\n",
      "cons.conf.idx                 0.0511     0.0050  10.1252 0.0000      0.0412     0.0610\n",
      "euribor3m                    -0.6082     0.0177 -34.3509 0.0000     -0.6429    -0.5735\n",
      "======================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before fitting the model, let's see the coefficients and the significance of our features, based on the train set\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "logit_model = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "result = logit_model.fit(method = 'bfgs', maxiter = 1000)\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "ww5_e1Ndag69",
    "outputId": "a4ae6844-4317-413a-c9a5-3bff0010e0db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                28831\n",
      "Model:                          Logit   Df Residuals:                    28800\n",
      "Method:                           MLE   Df Model:                           30\n",
      "Date:                Mon, 30 Mar 2020   Pseudo R-squ.:                  0.1947\n",
      "Time:                        03:20:31   Log-Likelihood:                -8194.9\n",
      "converged:                       True   LL-Null:                       -10176.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===============================================================================================\n",
      "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                         -45.4012   1.76e+04     -0.003      0.998   -3.45e+04    3.44e+04\n",
      "job_admin.                      0.0266      0.055      0.483      0.629      -0.081       0.135\n",
      "job_blue-collar                -0.1488      0.075     -1.982      0.047      -0.296      -0.002\n",
      "job_entrepreneur               -0.0319      0.125     -0.255      0.799      -0.277       0.213\n",
      "job_retired                     0.3437      0.103      3.321      0.001       0.141       0.547\n",
      "job_services                   -0.2021      0.087     -2.317      0.020      -0.373      -0.031\n",
      "job_student                     0.2830      0.116      2.434      0.015       0.055       0.511\n",
      "job_unemployed                  0.0294      0.126      0.233      0.816      -0.218       0.276\n",
      "marital_married                 0.0369      0.069      0.536      0.592      -0.098       0.172\n",
      "marital_single                  0.0791      0.079      1.005      0.315      -0.075       0.233\n",
      "education_basic                 0.0250      0.063      0.398      0.690      -0.098       0.148\n",
      "education_university.degree     0.0671      0.052      1.284      0.199      -0.035       0.169\n",
      "education_unknown               0.0404      0.104      0.388      0.698      -0.164       0.245\n",
      "default_no                      8.8717    216.713      0.041      0.967    -415.878     433.622\n",
      "default_unknown                 8.5946    216.713      0.040      0.968    -416.155     433.345\n",
      "contact_cellular              -22.4519   1.76e+04     -0.001      0.999   -3.45e+04    3.45e+04\n",
      "contact_telephone             -22.9493   1.76e+04     -0.001      0.999   -3.45e+04    3.45e+04\n",
      "month_apr                      -0.1028      0.082     -1.253      0.210      -0.264       0.058\n",
      "month_dec                       0.4318      0.185      2.328      0.020       0.068       0.795\n",
      "month_jul                       0.2350      0.069      3.401      0.001       0.100       0.370\n",
      "month_mar                       1.0068      0.127      7.902      0.000       0.757       1.257\n",
      "month_may                      -0.6966      0.065    -10.730      0.000      -0.824      -0.569\n",
      "month_oct                       0.1187      0.107      1.112      0.266      -0.091       0.328\n",
      "month_sep                      -0.2631      0.116     -2.271      0.023      -0.490      -0.036\n",
      "day_of_week_mon                -0.2414      0.054     -4.442      0.000      -0.348      -0.135\n",
      "day_of_week_thu                -0.0382      0.052     -0.732      0.464      -0.140       0.064\n",
      "age                            -0.0004      0.002     -0.169      0.866      -0.005       0.004\n",
      "campaign                       -0.0590      0.011     -5.182      0.000      -0.081      -0.037\n",
      "previous                        0.1109      0.033      3.357      0.001       0.046       0.176\n",
      "cons.price.idx                  0.6554      0.048     13.621      0.000       0.561       0.750\n",
      "cons.conf.idx                   0.0511      0.005     10.125      0.000       0.041       0.061\n",
      "euribor3m                      -0.6082      0.018    -34.351      0.000      -0.643      -0.573\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ll15Msovd3Wn"
   },
   "source": [
    "Here we can see, across 31 features, only 15 features are significant for describing the likelihood to be in Target Yes -- 8 are positive influence, while other 7 are negative influence.\n",
    "\n",
    "> Significance:\n",
    "(p-val < 0.05) :\n",
    "\n",
    "> Positive features and the coefficients\n",
    "- job_retired (0.3437)\n",
    "- job_student (0.2830)\n",
    "- month_dec (0.4318)\n",
    "- month_jul (0.2350)\n",
    "- month_mar (1.0068)\n",
    "- previous (0.1109)\n",
    "- cons.price.idx (0.6554)\n",
    "- cons.conf.idx (0.0511)\n",
    "\n",
    "> Negative features and the coefficients\n",
    "- job_blue-collar (-0.1488)\n",
    "- job_services (-0.2021)\n",
    "- month_sep (-0.2631)\n",
    "- month_may (-0.6966)\n",
    "- day_of_week_mon (-0.2414)\n",
    "- campaign (-0.0590)\n",
    "- euribor3m (-0.6082)\n",
    "\n",
    "One thing I like in logistic regression is the ability to help us see what features helps to increase/decrease the likelihood of Target Yes. The ones with positive coefficients here help us to describe that it increase to possibility to be in Target Yes. For example here, being student and retired are more likely to accept the offer from the bank campaign -- so we know that these are the preferred target consumer. On the other hand, people who work blue-collar job or in services sector are less likely to be in Target Yes. We also see that contact in March is more likely for customer to be accept this offer, in contrast is May. So it is better to advise to bank manager to call customers in March rather than in May.\n",
    "\n",
    "Now we will try to re-fit our model with the only significant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BCyhXgyqdH8N",
    "outputId": "6fa30b08-8bd6-4f5a-da83-3b0555039b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n"
     ]
    }
   ],
   "source": [
    "logitsig = banksig[['job_retired', 'job_student','month_dec', 'month_jul', 'month_mar', 'previous', 'cons.price.idx', 'cons.conf.idx',\n",
    "'job_blue-collar', 'job_services', 'month_sep', 'month_may','day_of_week_mon', 'campaign', 'euribor3m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "colab_type": "code",
    "id": "v4a_mSUofg1E",
    "outputId": "fb0300df-b688-4510-9fca-564e3d70a9ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_student</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>previous</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_services</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>month_may</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>campaign</th>\n",
       "      <th>euribor3m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_retired  job_student  ...  campaign  euribor3m\n",
       "0                0            0  ...         1      4.857\n",
       "1                0            0  ...         1      4.857\n",
       "2                0            0  ...         1      4.857\n",
       "3                0            0  ...         1      4.857\n",
       "4                0            0  ...         1      4.857\n",
       "...            ...          ...  ...       ...        ...\n",
       "41183            1            0  ...         1      1.028\n",
       "41184            0            0  ...         1      1.028\n",
       "41185            1            0  ...         2      1.028\n",
       "41186            0            0  ...         1      1.028\n",
       "41187            1            0  ...         3      1.028\n",
       "\n",
       "[41188 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitsig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYkcVMIFgC8C"
   },
   "source": [
    "## Trial 1 --  using only the significant features based on sm Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPXw2ko2fnFw"
   },
   "outputs": [],
   "source": [
    "## TRIAL 1 -- splitting the dataset (without scaling)\n",
    "\n",
    "Xtr_try1, Xts_try1, ytr_try1, yts_try1 = train_test_split(logitsig, target, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "WYs5rWjhgAhe",
    "outputId": "0b417c97-a919-4791-f904-ebfd152cd54d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fitting the model\n",
    "\n",
    "log_reg.fit(Xtr_try1, ytr_try1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lA_cRHkygTaZ"
   },
   "outputs": [],
   "source": [
    "tr_try1_pred = log_reg.predict(Xtr_try1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rcks3vhCgbMK",
    "outputId": "16b1f853-f8b3-447b-9c73-b83c3d577687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42190016103059585"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytr_try1, tr_try1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "P4sVLB1Hgf0I",
    "outputId": "18ea617d-d246-4484-af70-933625a7def0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20991  4579]\n",
      " [ 1165  2096]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ytr_try1, tr_try1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muXRzAjBglN1"
   },
   "outputs": [],
   "source": [
    "ts_try1_pred = log_reg.predict(Xts_try1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O8zbgODFgsjF",
    "outputId": "3db51ba2-4239-4796-a4ce-a786be7208ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4132947976878613"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yts_try1, ts_try1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "C5uXhx2Zgw92",
    "outputId": "e9bc983e-1766-457e-c5da-fd74eb2076c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9063 1915]\n",
      " [ 521  858]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yts_try1, ts_try1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "b_tF5UUQg6ON",
    "outputId": "3e8198c3-1b5c-48f7-ca56-4eb61d5cc421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.88     10978\n",
      "           1       0.31      0.62      0.41      1379\n",
      "\n",
      "    accuracy                           0.80     12357\n",
      "   macro avg       0.63      0.72      0.65     12357\n",
      "weighted avg       0.87      0.80      0.83     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yts_try1, ts_try1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBjJ49zShUoA"
   },
   "source": [
    "Here we see a slight improvement from our model, the number of True positives increased to 858 (earlier with all features are only 833). The recall also increased, however the f1 score stays the same (but at least I did not get error without scaling) -- now let's move on with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTrYhtz0prTX"
   },
   "outputs": [],
   "source": [
    "Xtr_try1scale = scaler.fit_transform(Xtr_try1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bD4pGaSprgW"
   },
   "outputs": [],
   "source": [
    "Xts_try1scale = scaler.transform(Xts_try1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "niGgUwhUprso",
    "outputId": "7224e820-1ab8-4f92-b167-62971ebab1ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(Xtr_try1scale, ytr_try1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmXVBfOspr7l"
   },
   "outputs": [],
   "source": [
    "tr_try1_predscale = log_reg.predict(Xtr_try1scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kIlUyX4BpsMT",
    "outputId": "96a573bc-2bcc-4fc5-912a-b8d0e5593140"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4404292597459483"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytr_try1, tr_try1_predscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "SxXrpB7Pq5oV",
    "outputId": "55650e09-f8e8-490b-e7dc-f64877071b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.89     25570\n",
      "           1       0.34      0.62      0.44      3261\n",
      "\n",
      "    accuracy                           0.82     28831\n",
      "   macro avg       0.64      0.73      0.67     28831\n",
      "weighted avg       0.88      0.82      0.84     28831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytr_try1, tr_try1_predscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqrlNpF4qITv"
   },
   "outputs": [],
   "source": [
    "ts_try1_predscale = log_reg.predict(Xts_try1scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V3KIUGIbqIjw",
    "outputId": "d241e4e2-fd11-43dd-d437-1d3bf0646d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4304130491975796"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yts_try1, ts_try1_predscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Wexn8ivyqIxm",
    "outputId": "ada5c0dc-e3f5-4f37-8d0e-2fe622502276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.90     10978\n",
      "           1       0.34      0.59      0.43      1379\n",
      "\n",
      "    accuracy                           0.82     12357\n",
      "   macro avg       0.64      0.72      0.66     12357\n",
      "weighted avg       0.88      0.82      0.84     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yts_try1, ts_try1_predscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1M5RNuCLqJB-",
    "outputId": "dd453a19-eb4f-46cf-d782-d6c0982f5155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9374 1604]\n",
      " [ 561  818]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yts_try1, ts_try1_predscale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBBiXIdRrGRV"
   },
   "source": [
    "Using the scaling data improved our F1 score -- it actually tried to balance the precision and recall, by improving the precision score. We can see that the model can predict True negatives more than misclassify them. However the number of True Positives decreased 40 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDQUCTFRhpAg"
   },
   "source": [
    "## Trial 2\n",
    "Since logistic regression is sensitive with outliers, now I am thinking of removing the outliers from numerical features -- first I will try cons.price.idx. Based on EDA we did before (I assume mainly caused by class imbalance), we found out that it is not normally distributed. Thus I will  remove the outliers based on median/IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXC5aVLjhAQK"
   },
   "outputs": [],
   "source": [
    "##find the outlier\n",
    "Q1_amd = banksig['cons.price.idx'].describe()['25%']\n",
    "Q3_amd = banksig['cons.price.idx'].describe()['75%']\n",
    "IQR = Q3_amd - Q1_amd\n",
    "\n",
    "#yang bukan outlier\n",
    "nout_amd = banksig[(banksig['cons.price.idx'] >= Q1_amd - (1.5*IQR)) & (banksig['cons.price.idx'] <= Q3_amd + (1.5 * IQR))]['cons.price.idx'].index\n",
    "\n",
    "#yang outlier\n",
    "# out_amd = banksig[(banksig['age'] < Q1_amd - (1.5*IQR)) | (banksig['age'] > Q3_amd + (1.5 * IQR))]['age'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AUmOVP-jdBN"
   },
   "outputs": [],
   "source": [
    "bank_nooutliers1 = banksig.loc[nout_amd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "FJ5TgclmjpOe",
    "outputId": "67841a1a-8272-4dd6-82a9-890eb15279a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41188 entries, 0 to 41187\n",
      "Data columns (total 31 columns):\n",
      "job_admin.                     41188 non-null int64\n",
      "job_blue-collar                41188 non-null int64\n",
      "job_entrepreneur               41188 non-null int64\n",
      "job_retired                    41188 non-null int64\n",
      "job_services                   41188 non-null int64\n",
      "job_student                    41188 non-null int64\n",
      "job_unemployed                 41188 non-null int64\n",
      "marital_married                41188 non-null int64\n",
      "marital_single                 41188 non-null int64\n",
      "education_basic                41188 non-null int64\n",
      "education_university.degree    41188 non-null int64\n",
      "education_unknown              41188 non-null int64\n",
      "default_no                     41188 non-null int64\n",
      "default_unknown                41188 non-null int64\n",
      "contact_cellular               41188 non-null int64\n",
      "contact_telephone              41188 non-null int64\n",
      "month_apr                      41188 non-null int64\n",
      "month_dec                      41188 non-null int64\n",
      "month_jul                      41188 non-null int64\n",
      "month_mar                      41188 non-null int64\n",
      "month_may                      41188 non-null int64\n",
      "month_oct                      41188 non-null int64\n",
      "month_sep                      41188 non-null int64\n",
      "day_of_week_mon                41188 non-null int64\n",
      "day_of_week_thu                41188 non-null int64\n",
      "age                            41188 non-null int64\n",
      "campaign                       41188 non-null int64\n",
      "previous                       41188 non-null int64\n",
      "cons.price.idx                 41188 non-null float64\n",
      "cons.conf.idx                  41188 non-null float64\n",
      "euribor3m                      41188 non-null float64\n",
      "dtypes: float64(3), int64(28)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Turns out we don't have outliers in here\n",
    "bank_nooutliers1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "CayjXR5Njro6",
    "outputId": "5803cdd9-39b1-4999-b212-82203f1012c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f06254bb4e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD6CAYAAACvZ4z8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMys4B72ZWcE56M3MCu7/AzUJQmvBpykgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check the other features using boxplot\n",
    "\n",
    "sns.boxplot(data = banksig[['cons.conf.idx', 'euribor3m', 'campaign', 'previous', 'cons.price.idx']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjmS0PwzlDVv"
   },
   "outputs": [],
   "source": [
    "# The one which have a lot of outliers is campaign, so let's remove this one\n",
    "##find the outlier\n",
    "Q1_camp = banksig['campaign'].describe()['25%']\n",
    "Q3_camp = banksig['campaign'].describe()['75%']\n",
    "IQRc = Q3_camp - Q1_camp\n",
    "\n",
    "#yang bukan outlier\n",
    "nout_camp = banksig[(banksig['campaign'] >= Q1_camp - (1.5*IQR)) & (banksig['campaign'] <= Q3_camp + (1.5 * IQR))]['campaign'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDYx2b9joUO6"
   },
   "outputs": [],
   "source": [
    "bank_nooutliers2 = banksig.loc[nout_camp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "wQk5qBbnoW88",
    "outputId": "ecda839a-ce1d-4a35-c5f8-157ecb76f1ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36204 entries, 0 to 41187\n",
      "Data columns (total 31 columns):\n",
      "job_admin.                     36204 non-null int64\n",
      "job_blue-collar                36204 non-null int64\n",
      "job_entrepreneur               36204 non-null int64\n",
      "job_retired                    36204 non-null int64\n",
      "job_services                   36204 non-null int64\n",
      "job_student                    36204 non-null int64\n",
      "job_unemployed                 36204 non-null int64\n",
      "marital_married                36204 non-null int64\n",
      "marital_single                 36204 non-null int64\n",
      "education_basic                36204 non-null int64\n",
      "education_university.degree    36204 non-null int64\n",
      "education_unknown              36204 non-null int64\n",
      "default_no                     36204 non-null int64\n",
      "default_unknown                36204 non-null int64\n",
      "contact_cellular               36204 non-null int64\n",
      "contact_telephone              36204 non-null int64\n",
      "month_apr                      36204 non-null int64\n",
      "month_dec                      36204 non-null int64\n",
      "month_jul                      36204 non-null int64\n",
      "month_mar                      36204 non-null int64\n",
      "month_may                      36204 non-null int64\n",
      "month_oct                      36204 non-null int64\n",
      "month_sep                      36204 non-null int64\n",
      "day_of_week_mon                36204 non-null int64\n",
      "day_of_week_thu                36204 non-null int64\n",
      "age                            36204 non-null int64\n",
      "campaign                       36204 non-null int64\n",
      "previous                       36204 non-null int64\n",
      "cons.price.idx                 36204 non-null float64\n",
      "cons.conf.idx                  36204 non-null float64\n",
      "euribor3m                      36204 non-null float64\n",
      "dtypes: float64(3), int64(28)\n",
      "memory usage: 8.8 MB\n"
     ]
    }
   ],
   "source": [
    "# we removed approximately 6000 rows. let's check whether using this data set will improve our prediction\n",
    "bank_nooutliers2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QT0qMprNrzKd"
   },
   "outputs": [],
   "source": [
    "target_try2 = target.loc[nout_camp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zK4CCj1PodeL"
   },
   "outputs": [],
   "source": [
    "Xtr_try2, Xts_try2, ytr_try2, yts_try2 = train_test_split(bank_nooutliers2, target_try2, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kll6SuPor_YK",
    "outputId": "0143e3fd-3d2e-4dd4-f4e4-b40604e2bd44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try without scaling\n",
    "log_reg.fit(Xtr_try2, ytr_try2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUJiZzdCsFIw"
   },
   "outputs": [],
   "source": [
    "tr_try2_pred = log_reg.predict(Xtr_try2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BC5y9nn4sQI8",
    "outputId": "5c56c0fd-dfd6-436f-a472-db645fcdd479"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42368729364149543"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytr_try2, tr_try2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "98YjAePLsTph",
    "outputId": "4e95793a-95f8-45cf-c323-72a2f7e80b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.80      0.87     22371\n",
      "           1       0.31      0.67      0.42      2971\n",
      "\n",
      "    accuracy                           0.79     25342\n",
      "   macro avg       0.63      0.74      0.65     25342\n",
      "weighted avg       0.87      0.79      0.82     25342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytr_try2, tr_try2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09EPGOYEsbmE"
   },
   "outputs": [],
   "source": [
    "ts_try2_pred = log_reg.predict(Xts_try2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WU2JYUJDsmaB",
    "outputId": "7c6b143d-bbbb-4065-984a-419187184770"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.425376762275158"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yts_try2, ts_try2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ZvMY39hKsqOg",
    "outputId": "6e810db8-a7c9-4cc3-e043-aed99e37d421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.87      9499\n",
      "           1       0.32      0.64      0.43      1363\n",
      "\n",
      "    accuracy                           0.78     10862\n",
      "   macro avg       0.63      0.72      0.65     10862\n",
      "weighted avg       0.86      0.78      0.81     10862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yts_try2, ts_try2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xb0It34-st_4",
    "outputId": "e089a1f7-25db-4f06-dfe8-0bcc7ee47659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7623 1876]\n",
      " [ 488  875]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yts_try2, ts_try2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQONB3pks9kQ"
   },
   "source": [
    "Here we see a great improvement towards predicting the True Positives. However there is also a trade-off, more misclassification of Target No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eyx_Keius0An"
   },
   "outputs": [],
   "source": [
    "# let's try using the scaling one\n",
    "\n",
    "Xtr_try2scale = scaler.fit_transform(Xtr_try2)\n",
    "Xts_try2scale = scaler.transform(Xts_try2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "JzU1eLbQtZvq",
    "outputId": "02d9aae2-8812-4f21-828f-36e5e1d7bcd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "log_reg.fit(Xtr_try2scale, ytr_try2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1N2-TKXytfl_"
   },
   "outputs": [],
   "source": [
    "tr_try2_predscale = log_reg.predict(Xtr_try2scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PfG56sEatocH",
    "outputId": "601ba31d-aa09-43f7-ad89-ca7f4805c86b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4398555630783119"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytr_try2, tr_try2_predscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "XJpSSgr7tudQ",
    "outputId": "9f79cb8e-709c-4478-9c61-37765fd035f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88     22371\n",
      "           1       0.33      0.66      0.44      2971\n",
      "\n",
      "    accuracy                           0.80     25342\n",
      "   macro avg       0.64      0.74      0.66     25342\n",
      "weighted avg       0.88      0.80      0.83     25342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytr_try2, tr_try2_predscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qty0HGFJtz9F"
   },
   "outputs": [],
   "source": [
    "ts_try2_predscale = log_reg.predict(Xts_try2scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r3r6Mzgat5oW",
    "outputId": "e4a976b7-e54d-4393-a65e-36d4f0d7aa14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4405648267008986"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yts_try2, ts_try2_predscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "4Ofy4vlCt89t",
    "outputId": "1a5d43c5-23fd-4ddb-affd-435526c2e66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88      9499\n",
      "           1       0.34      0.63      0.44      1363\n",
      "\n",
      "    accuracy                           0.80     10862\n",
      "   macro avg       0.64      0.73      0.66     10862\n",
      "weighted avg       0.86      0.80      0.82     10862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yts_try2, ts_try2_predscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "adRv9J_KuAD8",
    "outputId": "d4373abf-06ed-4bbe-8a8e-e49ddc61cfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7825 1674]\n",
      " [ 505  858]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yts_try2, ts_try2_predscale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r315EdD0vM9Z"
   },
   "source": [
    "We actually did not see a great improvement here using the scaled data (surprisingly our original data is better -- although we need to see the stability of the model first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWL7IwcUvqIL"
   },
   "source": [
    "## Trial 3 -- Introducing threshold\n",
    "This is the last strategy I will try in here. We already put a balanced weight for both classes by using the method in logistic regression model, first I will try using threshold instead of modifying the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "_qDyrBv3uE8I",
    "outputId": "f356d6fe-61df-4a2c-8c43-bfaf3e42f198"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Back to the original dataset\n",
    "# Actually now I am curious what if we just fit to unscaled data -- but I must admit that fitting to the scaled data is faster\n",
    "# I got a convergence warning though, I am afraid actually it did not converge --  so just go back to the scaled one\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "FyZAX8clyf7Q",
    "outputId": "8e9cda0a-edb5-43dd-ddc4-a8f5a8ea46ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much faster in fitting\n",
    "log_reg.fit(X_trainscale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "uk10kiNRyNG2",
    "outputId": "ee5bf7a7-d0c9-4375-dda5-3a2f6189a357"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81156501, 0.18843499],\n",
       "       [0.70933899, 0.29066101],\n",
       "       [0.78252392, 0.21747608],\n",
       "       ...,\n",
       "       [0.61975384, 0.38024616],\n",
       "       [0.68362271, 0.31637729],\n",
       "       [0.70717324, 0.29282676]])"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictProb = log_reg.predict_proba(X_testscale)\n",
    "PredictProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Kui_kQNyvVm"
   },
   "outputs": [],
   "source": [
    "# since I assume in the default model they used 0.5 threshold, now let's try using a higher probability \n",
    "# threshold for Target No predictions\n",
    "\n",
    "prediction = []\n",
    "for pred in PredictProb[:,0]:\n",
    "    if (pred > 0.70):\n",
    "        prediction.append(0)\n",
    "    else:\n",
    "        prediction.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "jDHVrKlizPMF",
    "outputId": "10c178b9-75a7-4aad-bdb9-21e660ad5304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.41      0.57     10978\n",
      "           1       0.16      0.87      0.26      1379\n",
      "\n",
      "    accuracy                           0.46     12357\n",
      "   macro avg       0.56      0.64      0.42     12357\n",
      "weighted avg       0.87      0.46      0.54     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now let's see if we make any difference\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ayuaEmQGzW6f",
    "outputId": "c50f6f71-ea4b-46e0-ec22-1622e997bf56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4478 6500]\n",
      " [ 186 1193]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDN5LYAUzgrC"
   },
   "source": [
    "Okay probably this is too much. Let's try to lower down our threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB7LFBMozch0"
   },
   "outputs": [],
   "source": [
    "prediction2 = []\n",
    "for pred in PredictProb[:,0]:\n",
    "    if (pred > 0.6):\n",
    "        prediction2.append(0)\n",
    "    else:\n",
    "        prediction2.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cJcsJ2g9zwwI",
    "outputId": "e9d71224-2023-41d8-b734-821cb43728e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7907 3071]\n",
      " [ 401  978]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "wXyPmJvrzzPT",
    "outputId": "9b4bd2d8-bfbe-4d21-e072-4c0309a93ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.72      0.82     10978\n",
      "           1       0.24      0.71      0.36      1379\n",
      "\n",
      "    accuracy                           0.72     12357\n",
      "   macro avg       0.60      0.71      0.59     12357\n",
      "weighted avg       0.87      0.72      0.77     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWpxpdZe1Cp3"
   },
   "source": [
    "Here we see that introducing the threshold improved our recall score, but our f1 and precision scores are really poor. We adjusted the model to predict more Target Yes, but in a cost of misclassifying the Target No (it's a quite significant number and also resources the bank needs to expend)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrPVYU6s1uyt"
   },
   "source": [
    "Now let's see what happen if we modify the class weight\n",
    "\n",
    "Specifically, the balanced argument will automatically weigh classes inversely proportional to their frequency:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HfFC66pLz5XK",
    "outputId": "0ad04479-4f9f-4cdf-8cd9-8ad03500a17c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56376613, 4.42057651])"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let's see our class weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# calculate class weighting\n",
    "weighting = compute_class_weight('balanced', [0,1], y_train)\n",
    "weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uK7Qc9rX3H-5"
   },
   "source": [
    "Here we see that our class weight is quite extreme already, the weight of Target No is only 0.5, while the weight for Target Yes is 8 times bigger. \n",
    "Let's try if we modify the class weight so it will be heavier for our Target Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34Te2Wg_0CTG"
   },
   "outputs": [],
   "source": [
    "## let's put our class weight for Target Yes as 5\n",
    "# redefine our model\n",
    "\n",
    "log_reg2 = LogisticRegression(solver = 'saga', penalty = 'l1', class_weight = {0 : 0.5, 1 : 5}, max_iter = 1500, C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "87sxG0eK0EfS",
    "outputId": "02fb7cdb-0a72-4b0c-e3cf-646fd9870f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={0: 0.5, 1: 5}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=1500, multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg2.fit(X_trainscale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xlo-egbI4BSm",
    "outputId": "6a0d5929-f306-4f62-844d-363997bfff8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3938257608790442"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, log_reg2.predict(X_trainscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "r8LtgUFF4Jvv",
    "outputId": "66a59d20-8160-41f6-efd6-613b77127609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85     25570\n",
      "           1       0.28      0.69      0.39      3261\n",
      "\n",
      "    accuracy                           0.76     28831\n",
      "   macro avg       0.61      0.73      0.62     28831\n",
      "weighted avg       0.87      0.76      0.80     28831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, log_reg2.predict(X_trainscale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XPP3o7sT4Sc2",
    "outputId": "9d3f4f34-b540-490a-be18-cda5540d43c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19622  5948]\n",
      " [ 1003  2258]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, log_reg2.predict(X_trainscale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MmCpmN-4YsU"
   },
   "outputs": [],
   "source": [
    "weight_test = log_reg2.predict(X_testscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "bdM5YHHw4e1s",
    "outputId": "7709ef52-a988-4c88-a6b9-3f800ae0cc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85     10978\n",
      "           1       0.27      0.67      0.39      1379\n",
      "\n",
      "    accuracy                           0.76     12357\n",
      "   macro avg       0.61      0.72      0.62     12357\n",
      "weighted avg       0.87      0.76      0.80     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, weight_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-lNFjhCw4jsF",
    "outputId": "abdb92e9-57ff-4869-e99a-eb58635417af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8481 2497]\n",
      " [ 453  926]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, weight_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAI3qz7d8CwT"
   },
   "source": [
    "We see an improvement in predicting the Target Yes, but as before, the misclassification of Target No is increasing. The percentage of Target Yes prediction is about 67%, compared to Target No 77%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XC4GrUyW8unV"
   },
   "source": [
    "## Trial 4 -- using information we got from all other trials.\n",
    "Here I will first remove the campaign outlier (trial 2), then use only the significant features (trial 1), and comparing the class weight (balanced and self-set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3w5wowC94saO"
   },
   "outputs": [],
   "source": [
    "## back to trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "tjAbn9O5-Y8q",
    "outputId": "652f7b10-80f1-4c65-bcea-7dedecbf0818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36204 entries, 0 to 41187\n",
      "Data columns (total 31 columns):\n",
      "job_admin.                     36204 non-null int64\n",
      "job_blue-collar                36204 non-null int64\n",
      "job_entrepreneur               36204 non-null int64\n",
      "job_retired                    36204 non-null int64\n",
      "job_services                   36204 non-null int64\n",
      "job_student                    36204 non-null int64\n",
      "job_unemployed                 36204 non-null int64\n",
      "marital_married                36204 non-null int64\n",
      "marital_single                 36204 non-null int64\n",
      "education_basic                36204 non-null int64\n",
      "education_university.degree    36204 non-null int64\n",
      "education_unknown              36204 non-null int64\n",
      "default_no                     36204 non-null int64\n",
      "default_unknown                36204 non-null int64\n",
      "contact_cellular               36204 non-null int64\n",
      "contact_telephone              36204 non-null int64\n",
      "month_apr                      36204 non-null int64\n",
      "month_dec                      36204 non-null int64\n",
      "month_jul                      36204 non-null int64\n",
      "month_mar                      36204 non-null int64\n",
      "month_may                      36204 non-null int64\n",
      "month_oct                      36204 non-null int64\n",
      "month_sep                      36204 non-null int64\n",
      "day_of_week_mon                36204 non-null int64\n",
      "day_of_week_thu                36204 non-null int64\n",
      "age                            36204 non-null int64\n",
      "campaign                       36204 non-null int64\n",
      "previous                       36204 non-null int64\n",
      "cons.price.idx                 36204 non-null float64\n",
      "cons.conf.idx                  36204 non-null float64\n",
      "euribor3m                      36204 non-null float64\n",
      "dtypes: float64(3), int64(28)\n",
      "memory usage: 8.8 MB\n"
     ]
    }
   ],
   "source": [
    "bank_nooutliers2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaZYOjAo9fGU"
   },
   "outputs": [],
   "source": [
    "logitsig2 = bank_nooutliers2[['job_retired', 'job_student','month_dec', 'month_jul', 'month_mar', 'previous', 'cons.price.idx', 'cons.conf.idx',\n",
    "'job_blue-collar', 'job_services', 'month_sep', 'month_may','day_of_week_mon', 'campaign', 'euribor3m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BVZdLBj9rPf"
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "\n",
    "Xtr_try4, Xts_try4, ytr_try4, yts_try4 = train_test_split(logitsig2, target_try2, test_size = 0.3, random_state = 101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7W4Uhq4-z8Z"
   },
   "outputs": [],
   "source": [
    "# balanced logreg\n",
    "# scaling the X\n",
    "\n",
    "Xtr_try4scale = scaler.fit_transform(Xtr_try4)\n",
    "Xts_try4scale = scaler.transform(Xts_try4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "wScgfB8s_Z-B",
    "outputId": "30d38aca-b59c-4480-b4d2-7cae271f1cb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(Xtr_try4scale, ytr_try4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSu5rj5L_em1"
   },
   "outputs": [],
   "source": [
    "tr_try4_pred = log_reg.predict(Xtr_try4scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LbsodSPp_nru",
    "outputId": "fd3c0d13-db92-4ea6-9bde-3497a79de206"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44517569632154186"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytr_try4, tr_try4_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZXpxVVl_rED"
   },
   "outputs": [],
   "source": [
    "ts_try4_pred = log_reg.predict(Xts_try4scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RBdVLBkO_wyJ",
    "outputId": "32900357-d8df-452e-84f4-b76d931c915b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45005370569280345"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yts_try4, ts_try4_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "uqzgxyNU_0Pz",
    "outputId": "4cfb708b-895d-4a1b-80ee-364bcd0e3eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89      9499\n",
      "           1       0.35      0.61      0.45      1363\n",
      "\n",
      "    accuracy                           0.81     10862\n",
      "   macro avg       0.65      0.73      0.67     10862\n",
      "weighted avg       0.87      0.81      0.83     10862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yts_try4, ts_try4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xVkuWNIE_5g5",
    "outputId": "203ee14f-4ce5-409f-f934-cc7f478684d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7976 1523]\n",
      " [ 525  838]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yts_try4, ts_try4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Q2euK1w6AJrH",
    "outputId": "8af97f2f-cb99-4b7d-9afe-32adc92afe81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={0: 0.5, 1: 5}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=1500, multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The self-set class weight\n",
    "\n",
    "log_reg2.fit(Xtr_try4scale, ytr_try4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wuzC3u-x_-f4",
    "outputId": "27cac627-10dd-4262-8c98-d9bfaf4595fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3830783078307831"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytr_try4, log_reg2.predict(Xtr_try4scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fA7VSi6-AamF"
   },
   "outputs": [],
   "source": [
    "ts_try4_pred2 = log_reg2.predict(Xts_try4scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DXBylryyBIO6",
    "outputId": "66ddcaa9-d09b-4570-826e-c7b46d7a74b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6971 2528]\n",
      " [ 422  941]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yts_try4, ts_try4_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "02m-gy5yBLkP",
    "outputId": "cb42c4b5-3430-40e3-f843-e6055ff36232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.83      9499\n",
      "           1       0.27      0.69      0.39      1363\n",
      "\n",
      "    accuracy                           0.73     10862\n",
      "   macro avg       0.61      0.71      0.61     10862\n",
      "weighted avg       0.86      0.73      0.77     10862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yts_try4, ts_try4_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g31mrdxEIejR"
   },
   "source": [
    "Here we see an improvement of the recall score in the self-set class weight. We also increased around 100 Target Yes, but it should be noted that we also increase the False Positive by 1000. \n",
    "\n",
    "Personally while I prefer to have more True Positive cases, but I think considering how much bank will lose is also important -- thus for now on I will use the balanced weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQpq7K15IdY0"
   },
   "outputs": [],
   "source": [
    "# let's see once again the feature coefficients here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "ieIQFJrwBPex",
    "outputId": "47cd84c1-6d6d-4bb7-ccea-d9506640958b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2542: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.291223\n",
      "         Iterations: 135\n",
      "         Function evaluations: 140\n",
      "         Gradient evaluations: 140\n",
      "                          Results: Logit\n",
      "===================================================================\n",
      "Model:                Logit            Pseudo R-squared: 0.194     \n",
      "Dependent Variable:   y                AIC:              14792.3246\n",
      "Date:                 2020-03-30 06:08 BIC:              14922.5681\n",
      "No. Observations:     25342            Log-Likelihood:   -7380.2   \n",
      "Df Model:             15               LL-Null:          -9158.1   \n",
      "Df Residuals:         25326            LLR p-value:      0.0000    \n",
      "Converged:            1.0000           Scale:            1.0000    \n",
      "-------------------------------------------------------------------\n",
      "                 Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
      "-------------------------------------------------------------------\n",
      "const           -42.1177   3.9679 -10.6145 0.0000 -49.8947 -34.3407\n",
      "job_retired       0.3006   0.0841   3.5741 0.0004   0.1358   0.4655\n",
      "job_student       0.4069   0.1017   3.9998 0.0001   0.2075   0.6062\n",
      "month_dec         0.4392   0.1983   2.2145 0.0268   0.0505   0.8279\n",
      "month_jul         0.3172   0.0704   4.5086 0.0000   0.1793   0.4551\n",
      "month_mar         0.9260   0.1201   7.7136 0.0000   0.6907   1.1613\n",
      "previous          0.1633   0.0335   4.8801 0.0000   0.0977   0.2289\n",
      "cons.price.idx    0.4689   0.0434  10.8092 0.0000   0.3839   0.5539\n",
      "cons.conf.idx     0.0407   0.0042   9.7327 0.0000   0.0325   0.0488\n",
      "job_blue-collar  -0.2280   0.0616  -3.6996 0.0002  -0.3487  -0.1072\n",
      "job_services     -0.1692   0.0818  -2.0701 0.0384  -0.3295  -0.0090\n",
      "month_sep        -0.0169   0.1160  -0.1453 0.8845  -0.2443   0.2105\n",
      "month_may        -0.7798   0.0560 -13.9237 0.0000  -0.8895  -0.6700\n",
      "day_of_week_mon  -0.3288   0.0562  -5.8470 0.0000  -0.4390  -0.2186\n",
      "campaign         -0.0133   0.0238  -0.5566 0.5778  -0.0599   0.0334\n",
      "euribor3m        -0.6338   0.0173 -36.5936 0.0000  -0.6678  -0.5999\n",
      "===================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model2 = sm.Logit(ytr_try4, sm.add_constant(Xtr_try4))\n",
    "result = logit_model2.fit(method = 'bfgs', maxiter = 1000)\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KojkMIKqJqLY"
   },
   "source": [
    "Here we saw that all the features are significant, except for campaign and month_sep. Let's check our model once again (balanced weight) by omitting those two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8V8gMoffJoVy"
   },
   "outputs": [],
   "source": [
    "logitsig3 = bank_nooutliers2[['job_retired', 'job_student','month_dec', 'month_jul', 'month_mar', 'previous', 'cons.price.idx', 'cons.conf.idx',\n",
    "'job_blue-collar', 'job_services', 'month_may','day_of_week_mon', 'euribor3m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aoegTO0LDgtU"
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "\n",
    "Xtr_try5, Xts_try5, ytr_try5, yts_try5 = train_test_split(logitsig3, target_try2, test_size = 0.3, random_state = 101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xd0mrwqAKI2e"
   },
   "outputs": [],
   "source": [
    "#Scaling the Xs\n",
    "\n",
    "Xtr_try5scale = scaler.fit_transform(Xtr_try5)\n",
    "Xts_try5scale = scaler.transform(Xts_try5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "2BHJHxdBKTFE",
    "outputId": "92bc0e4c-4a51-49a6-f127-ba537b8d0334"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting the balanced model\n",
    "\n",
    "log_reg.fit(Xtr_try5scale, ytr_try5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fUpsB1FnKZPU",
    "outputId": "99713494-b325-4234-b9ce-416c50a92e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4454117647058824"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytr_try5, log_reg.predict(Xtr_try5scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGKdcTWvKjJX"
   },
   "outputs": [],
   "source": [
    "ts_try5_pred = log_reg.predict(Xts_try5scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cZnkiBhtKvPp",
    "outputId": "28fc57d2-0c32-49e9-d389-89cf53c5de26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.449384038564542"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yts_try5, ts_try5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WDeYnZuYKz4Z",
    "outputId": "e9f2cbee-3c13-4c73-936b-01a45b630134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7967 1532]\n",
      " [ 524  839]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yts_try5, ts_try5_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "HdIaMvUuK6py",
    "outputId": "9f845309-ec42-4243-a13f-0b67765d4a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89      9499\n",
      "           1       0.35      0.62      0.45      1363\n",
      "\n",
      "    accuracy                           0.81     10862\n",
      "   macro avg       0.65      0.73      0.67     10862\n",
      "weighted avg       0.86      0.81      0.83     10862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yts_try5, ts_try5_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1nRwFagMyvU"
   },
   "source": [
    "After we removed the features it does not seem to improve our model. We only increase the prediction of Target Yes by one, but misclassify 9 of True Negative. Let's stick with the one before this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Amjky0emNFhg"
   },
   "source": [
    "## Checking model stability\n",
    "\n",
    "For this part, we will use the :\n",
    "* original logistic regression model with a balanced class weight\n",
    "* the dataset with the removed campaign outliers and 15 significant features from the original sm.Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpswuiGAN4SS"
   },
   "outputs": [],
   "source": [
    "# The model\n",
    "log_reg = LogisticRegression(solver = 'saga', penalty = 'l1', class_weight = 'balanced', max_iter = 1500, C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tzmObo6OFkW"
   },
   "outputs": [],
   "source": [
    "# The dataset\n",
    "logitsig2 = bank_nooutliers2[['job_retired', 'job_student','month_dec', 'month_jul', 'month_mar', 'previous', 'cons.price.idx', 'cons.conf.idx',\n",
    "'job_blue-collar', 'job_services', 'month_sep', 'month_may','day_of_week_mon', 'campaign', 'euribor3m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHk_-fV1OM9E"
   },
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "\n",
    "Xtr_fin, Xts_fin, ytr_fin, yts_fin = train_test_split(logitsig2, target_try2, test_size = 0.3, random_state = 101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QMqC3L6Ocz-"
   },
   "outputs": [],
   "source": [
    "# Making metrics functions first\n",
    "\n",
    "def calc_train_error(X_train, y_train, model):\n",
    "    predictions = model.predict(X_train)\n",
    "    predictProba = model.predict_proba(X_train)\n",
    "    matt = matthews_corrcoef(y_train, predictions)\n",
    "    f1 = f1_score(y_train, predictions)\n",
    "    report = classification_report(y_train, predictions)\n",
    "    roc_auc = roc_auc_score(y_train, predictProba[:,1])\n",
    "    accuracy = accuracy_score(y_train, predictions)\n",
    "    confmatrix = confusion_matrix(y_train, predictions)\n",
    "    logloss = log_loss(y_train, predictProba)\n",
    "    return {\n",
    "        'report': report,\n",
    "        'matthew':matt,\n",
    "        'f1': f1,\n",
    "        'roc': roc_auc,\n",
    "        'accuracy': accuracy,\n",
    "        'confusion': confmatrix,\n",
    "        'logloss': logloss\n",
    "    }\n",
    "  \n",
    "def calc_validation_error(X_test, y_test, model):\n",
    "    predictions = model.predict(X_test)\n",
    "    predictProba = model.predict_proba(X_test)\n",
    "    matt = matthews_corrcoef(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    report = classification_report(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, predictProba[:,1])\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    confmatrix = confusion_matrix(y_test, predictions)\n",
    "    logloss = log_loss(y_test, predictProba)\n",
    "    return {\n",
    "        'report': report,\n",
    "        'matthew':matt,\n",
    "        'f1': f1,\n",
    "        'roc': roc_auc,\n",
    "        'accuracy': accuracy,\n",
    "        'confusion': confmatrix,\n",
    "        'logloss': logloss\n",
    "    }\n",
    "\n",
    "def calc_metrics(X_train, y_train, X_test, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    train_error = calc_train_error(X_train, y_train, model)\n",
    "    validation_error = calc_validation_error(X_test, y_test, model)\n",
    "    return train_error, validation_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErCf7vSnPJxG"
   },
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-C8zm2lzPFeO"
   },
   "outputs": [],
   "source": [
    "# For Logistic Regression\n",
    "k = 5\n",
    "kf_log = KFold(n_splits = k, shuffle = True, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQlmCeo_PNHw"
   },
   "outputs": [],
   "source": [
    "train_errors = []\n",
    "valid_errors = []\n",
    "\n",
    "for train_index, val_index in kf_log.split(logitsig2,target_try2):\n",
    "    \n",
    "    #split data\n",
    "    X_trn, X_val = logitsig2.iloc[train_index], logitsig2.iloc[val_index]\n",
    "    y_trn, y_val = target_try2.iloc[train_index], target_try2.iloc[val_index]\n",
    "    \n",
    "    #instantiate model -- taking the one with the best hyperparameter according to the randomsearch\n",
    "    log_reg = LogisticRegression(solver = 'saga', penalty = 'l1', class_weight = 'balanced', max_iter = 1500, C = 1)\n",
    "\n",
    "    #Scaling our X_train_log and X_val_log\n",
    "    X_tr_scale = scaler.fit_transform(X_trn)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "    #calculate error\n",
    "    train_error, valid_error = calc_metrics(X_tr_scale, y_trn, X_val_scale, y_val, log_reg)\n",
    "    \n",
    "    #append to appropriate list\n",
    "    train_errors.append(train_error)\n",
    "    valid_errors.append(valid_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "hn0skvy9P2Pa",
    "outputId": "68449541-ce7e-423a-ba89-17ba4e9e94e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train ROC AUC</th>\n",
       "      <th>Test ROC AUC</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Test F1 Score</th>\n",
       "      <th>Train Matthews Corr Coef</th>\n",
       "      <th>Test Matthews Corr Coef</th>\n",
       "      <th>Train Log Loss</th>\n",
       "      <th>Test Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 Iteration</th>\n",
       "      <td>0.815592</td>\n",
       "      <td>0.817014</td>\n",
       "      <td>0.784616</td>\n",
       "      <td>0.777790</td>\n",
       "      <td>0.449211</td>\n",
       "      <td>0.449522</td>\n",
       "      <td>0.371588</td>\n",
       "      <td>0.367524</td>\n",
       "      <td>0.536980</td>\n",
       "      <td>0.536026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 Iteration</th>\n",
       "      <td>0.811967</td>\n",
       "      <td>0.805828</td>\n",
       "      <td>0.785498</td>\n",
       "      <td>0.775970</td>\n",
       "      <td>0.444172</td>\n",
       "      <td>0.442948</td>\n",
       "      <td>0.365726</td>\n",
       "      <td>0.362005</td>\n",
       "      <td>0.537197</td>\n",
       "      <td>0.543043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 Iteration</th>\n",
       "      <td>0.816248</td>\n",
       "      <td>0.821295</td>\n",
       "      <td>0.781482</td>\n",
       "      <td>0.787572</td>\n",
       "      <td>0.453593</td>\n",
       "      <td>0.439341</td>\n",
       "      <td>0.374815</td>\n",
       "      <td>0.362510</td>\n",
       "      <td>0.537436</td>\n",
       "      <td>0.531861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Iteration</th>\n",
       "      <td>0.807755</td>\n",
       "      <td>0.805828</td>\n",
       "      <td>0.782554</td>\n",
       "      <td>0.785434</td>\n",
       "      <td>0.435981</td>\n",
       "      <td>0.457562</td>\n",
       "      <td>0.357549</td>\n",
       "      <td>0.375281</td>\n",
       "      <td>0.539586</td>\n",
       "      <td>0.541261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 Iteration</th>\n",
       "      <td>0.806967</td>\n",
       "      <td>0.806492</td>\n",
       "      <td>0.782875</td>\n",
       "      <td>0.784362</td>\n",
       "      <td>0.442517</td>\n",
       "      <td>0.430256</td>\n",
       "      <td>0.361744</td>\n",
       "      <td>0.357834</td>\n",
       "      <td>0.538299</td>\n",
       "      <td>0.540608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.811706</td>\n",
       "      <td>0.811291</td>\n",
       "      <td>0.783405</td>\n",
       "      <td>0.782226</td>\n",
       "      <td>0.445095</td>\n",
       "      <td>0.443926</td>\n",
       "      <td>0.366284</td>\n",
       "      <td>0.365031</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>0.538560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Train Accuracy  Test Accuracy  ...  Train Log Loss  Test Log Loss\n",
       "1 Iteration        0.815592       0.817014  ...        0.536980       0.536026\n",
       "2 Iteration        0.811967       0.805828  ...        0.537197       0.543043\n",
       "3 Iteration        0.816248       0.821295  ...        0.537436       0.531861\n",
       "4 Iteration        0.807755       0.805828  ...        0.539586       0.541261\n",
       "5 Iteration        0.806967       0.806492  ...        0.538299       0.540608\n",
       "Average            0.811706       0.811291  ...        0.537900       0.538560\n",
       "\n",
       "[6 rows x 10 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix  = []\n",
    "for i, j in zip(train_errors, valid_errors):\n",
    "    matrix.append([i['accuracy'], j['accuracy'], i['roc'], j['roc'], i['f1'], j['f1'], \n",
    "                   i['matthew'], j['matthew'], i['logloss'], j['logloss']])\n",
    "\n",
    "calc_matrix = pd.DataFrame(matrix, columns = ['Train Accuracy', 'Test Accuracy', 'Train ROC AUC', 'Test ROC AUC',\n",
    "                                             'Train F1 Score', 'Test F1 Score', 'Train Matthews Corr Coef', \n",
    "                                              'Test Matthews Corr Coef', 'Train Log Loss', 'Test Log Loss'])\n",
    "average = []\n",
    "for i in calc_matrix.columns:\n",
    "    average.append(calc_matrix[i].mean())\n",
    "    \n",
    "average_mat = pd.DataFrame(average).T\n",
    "average_mat.columns = ['Train Accuracy', 'Test Accuracy', 'Train ROC AUC', 'Test ROC AUC',\n",
    "                                             'Train F1 Score', 'Test F1 Score', 'Train Matthews Corr Coef', \n",
    "                                              'Test Matthews Corr Coef', 'Train Log Loss', 'Test Log Loss']\n",
    "index_label = []\n",
    "for i in range(1, len(calc_matrix)+1):\n",
    "    index_label.append(f'{i} Iteration')\n",
    "index_label.append('Average')\n",
    "calculation = pd.concat([calc_matrix, average_mat])\n",
    "calculation.index = index_label\n",
    "calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the KFold cross validation method, we can see here that our model is stable enough -- the score fluctuations are not extreme. The ROC-AUC scores are also quite satisfying, it is more than 0.5, indicating that our model does not randomly predict our cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10gp_w-VQKXT"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_log = Pipeline([('std_scl', StandardScaler()), \n",
    "                    ('log_reg', LogisticRegression(solver = 'saga', penalty = 'l1', class_weight = 'balanced', max_iter = 1500, C = 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "fOEiCoIaRPDh",
    "outputId": "d25b3f07-3fc7-4f3e-a262-86c7b326dfbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.79141504 0.79527651 0.75859248 0.81309594 0.79010414 0.77727506\n",
      " 0.79679525 0.78380738 0.790135   0.78541939]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAYTklEQVR4nO3df3BcZ33v8fensp0oIcQhVrn4R2y3\nGAdT0piregCXS8iP2gQmNjMtlbmh4wzTtDPE7Q2pi30HaJpbSoppU2hNmYSmGX7FdV3XFRCqwHUC\npBiuZWQwtqsgTBJLDlRJKhITQWzle/84R8mRsiut7NUe+dHnNbMzu895ztnvOVp/9uzzHO8qIjAz\ns3T9QtkFmJnZ5HLQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFv04KkyyT1Fh4flHRZLX1P4bk+\nIen9p7q+Wb056G1Mkt4hqVPScUmPSvqSpF8vu67TFRGvioj7T3c7ktZLemDUtn8/Iv7P6W7brF4c\n9FaVpPcAfw38OfBS4CLg48CaKv1nNK46qzf//dLloLeKJJ0P3AK8OyJ2RsRPI+JERHw+IjbmfW6W\ntEPSZyQ9CayXNFdSu6QnJPVI+t3CNlfknw6elPRjSX+Vt5+db+NxSQOS9kp6aYWa3itpx6i2j0r6\nWH7/OkmHJT0l6Yik3xtj/x6SdGV+v1nSXZL+S9Ih4NdG9d0k6Qf5dg9Jelve/krgE8Dr8k88A3n7\nXZL+rLD+7+bH4on82MwtLAtJvy/p+/m+b5WkKjVXPH75sl+X9I18G0clrR/+O0r6lKR+SQ9Lep+k\nX8iXrZf075Juk/Q4cLOksyR9RNIj+XN8QlJz3n+OpC/kz/GEpK8Pb8umuIjwzbcX3IDVwElgxhh9\nbgZOAGvJThqaga+RnfWfDVwK9AOX5/33AO/M778IeG1+//eAzwPnAE3AfwdeXOH5FgJPA+flj5uA\nRwvbeQvwy4CAN+Z9X5MvuwzoLWzrIeDK/P6twNeBlwALgO+N6vtbwNx8H38b+CnwsnzZeuCBUXXe\nBfxZfv9y4DHgNcBZwN8AXyv0DeALwGyyT0z9wOoqx7va8VsIPAWsA2YCFwKX5ss+BfwrcB6wCHgQ\neFeh9pPABmBG/ve7DWjPj8V5+d/lQ3n/D5G9sc3Mb28AVPZr1bfxb343tmouBB6LiJPj9NsTEbsi\n4llgDrASeG9E/Cwi9gOfBH4n73sCeLmkORFxPCK+WWi/EHh5RAxFxL6IeHL0E0XEw8C3gbflTZcD\nTw9vJyK+GBE/iMxXgXvJwmg8bwc+GBFPRMRR4GOjnvefIuJYRDwbEf8IfB9YUcN2Af4ncGdEfDsi\nfg5sJvsEsKjQ59aIGIiIR4D7yN4gK6l2/N4BfCUi7o7sU9fjEbFfUhPQBmyOiKci4iHgL4F3FrZ5\nLCL+Jv87/wy4HrgxPxZPkQ3btRWe/2XAwvx5vh4R/rKsM4CD3qp5HJhTw7jt0cL9ucBwQAx7GJiX\n338X8ArgP/Lhmbfm7Z8GOoBtko5J+rCkmVWe73NkZ66QBdznhhdIerOkb+bDCgPA1WRvPuOZO2o/\nHi4ulPQ7kvbnQxYDwK/UuN3hbT+3vYg4TnZs5xX6/Khw/2mys/VKqh2/BcAPKvSfQ3bmXdyf4t8D\nRu53C9mnqn2Fff23vB1gC9AD3JsPjW2qUqdNMQ56q2YP8HOyYZmxFM/ojgEvkXReoe0ioA8gIr4f\nEeuAXwT+Atgh6dz87PBPI2IZ8HrgrTz/KWC0fwIukzSf7Mz+cwCSzgL+GfgI8NKImA3cQzaMM55H\nycKyWDP5dhcCdwA3ABfm2/1eYbvjndEeIxtaGd7euWSfXvpqqGuEasePLKx/ucIqj5GdhS8stD33\n96hQ/2PAIPCqiJid386PiBflz/9URNwUEb8EXAO8R9IVE90PazwHvVUUET8BPgBslbRW0jmSZuZn\nzR+uss5R4BvAh/IJ1kvIzkI/AyDpWkkt+TDPQL7as5LeJOnV+VDDk2Th9GyV5+gH7gf+AfhhRBzO\nF80iGwPvB05KejPwGzXu7nZgs6QL8jeQDYVl55KFYX++D9eRndEP+zEwX9KsKtu+G7hO0qX5m9Gf\nA9/Kh1EmpNrxAz4LXCnp7ZJmSLpQ0qURMZTv2wclnZe/ab2H/O8xWr7dO4DbJP1i/pzzJK3K779V\n0svzyeKfAENU+TvZ1OKgt6oi4i/JguF9ZEF3lOzMdtcYq60jm/Q7BvwL8CcR8ZV82WrgoKTjwEeB\ntogYBP4bsIMs5A8DXyUbzqnmc8CVFIZt8uGiPyALtv8iG9Zpr3FX/5RsSOOHZOP6zz13RBwiG9fe\nQxbqrwb+vbDubuAg8CNJj43ecL7v7yf7tPEo2Zl32+h+Nap4/PKx/auBm4AngP3Ar+brbCCbPD4C\nPEB2zO4c4zneSzY8801lV1J9BViaL1uSPz5Odjw+HhH3neK+WAPJcylmZmnzGb2ZWeIc9GZmiXPQ\nm5klzkFvZpa4KfclRnPmzIlFixaVXYaZ2Rll3759j0VES6VlUy7oFy1aRGdnZ9llmJmdUSQ9XG2Z\nh27MzBLnoDczS5yD3swscQ56M7PEOejNzBI35a66sXTs6upjS0c3xwYGmTu7mY2rlrJ2+bzxVzSz\nunLQ26TY1dXH5p0HGDwxBEDfwCCbdx4AcNibNZiHbmxSbOnofi7khw2eGGJLR3dJFZlNXw56mxTH\nBgYn1G5mk8dBb5Ni7uzmCbWb2eRx0Nuk2LhqKc0zm0a0Nc9sYuOqpVXWMLPJ4slYmxTDE66+6sas\nfA56mzRrl89zsJtNAR66MTNLnIPezCxxDnozs8TVFPSSVkvqltQjaVOF5RdJuk9Sl6TvSro6b78w\nbz8u6W/rXbyZmY1v3KCX1ARsBd4MLAPWSVo2qtv7gO0RsRxoAz6et/8MeD/wR3Wr2MzMJqSWM/oV\nQE9EHImIZ4BtwJpRfQJ4cX7/fOAYQET8NCIeIAt8MzMrQS1BPw84Wnjcm7cV3QxcK6kXuAfYMJEi\nJF0vqVNSZ39//0RWNTOzcdRrMnYdcFdEzAeuBj4tqeZtR8TtEdEaEa0tLRV/xNzMzE5RLWHcBywo\nPJ6ftxW9C9gOEBF7gLOBOfUo0MzMTk8tQb8XWCJpsaRZZJOt7aP6PAJcASDplWRB7zEYM7MpYNyv\nQIiIk5JuADqAJuDOiDgo6RagMyLagZuAOyTdSDYxuz4iAkDSQ2QTtbMkrQV+IyIOTc7umJnZaDV9\n101E3EM2yVps+0Dh/iFgZZV1F51GfWZmdpr8P2PNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDcz\nS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejN\nzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56\nM7PE1RT0klZL6pbUI2lTheUXSbpPUpek70q6urBsc75et6RV9SzezMzGN2O8DpKagK3AVUAvsFdS\ne0QcKnR7H7A9Iv5O0jLgHmBRfr8NeBUwF/iKpFdExFC9d8TMzCqr5Yx+BdATEUci4hlgG7BmVJ8A\nXpzfPx84lt9fA2yLiJ9HxA+Bnnx7ZmbWILUE/TzgaOFxb95WdDNwraResrP5DRNYF0nXS+qU1Nnf\n319j6WZmVot6TcauA+6KiPnA1cCnJdW87Yi4PSJaI6K1paWlTiWZmRnUMEYP9AELCo/n521F7wJW\nA0TEHklnA3NqXNfMzCZRLWfde4ElkhZLmkU2udo+qs8jwBUAkl4JnA305/3aJJ0laTGwBPh/9Sre\nzMzGN+4ZfUSclHQD0AE0AXdGxEFJtwCdEdEO3ATcIelGsonZ9RERwEFJ24FDwEng3b7ixsyssZTl\n8dTR2toanZ2dZZdhZnZGkbQvIlorLfP/jDUzS5yD3swscbVcdWNmCdnV1ceWjm6ODQwyd3YzG1ct\nZe3yF/z3FkuIg95sGtnV1cfmnQcYPJFdE9E3MMjmnQcAHPYJ89CN2TSypaP7uZAfNnhiiC0d3SVV\nZI3goDebRo4NDE6o3dLgoDebRubObp5Qu6XBQW82jWxctZTmmU0j2ppnNrFx1dKSKrJG8GRsHflq\nBpvqhl+Pfp1OLw76OvHVDHamWLt8nl+T04yHburEVzOY2VTloK8TX81gZlOVg75OfDWDmU1VDvo6\n8dUMZjZVeTK2Tnw1g5lNVQ76OvLVDGY2FXnoxswscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PE\nJXN5pb850syssiSC3t8caWZWXRJDN/7mSDOz6pIIen9zpJlZdUkEvb850sysupqCXtJqSd2SeiRt\nqrD8Nkn789uDkgYKy/5C0vfy22/Xs/hh/uZIG8uurj5W3rqbxZu+yMpbd7Orq6/skmyKmC6vjXEn\nYyU1AVuBq4BeYK+k9og4NNwnIm4s9N8ALM/vvwV4DXApcBZwv6QvRcST9dwJf3OkVeOJeqtmOr02\narnqZgXQExFHACRtA9YAh6r0Xwf8SX5/GfC1iDgJnJT0XWA1sP20qq7A3xxplYw1Ue/Xy/Q2nV4b\ntQzdzAOOFh735m0vIGkhsBjYnTd9B1gt6RxJc4A3AQsqrHe9pE5Jnf39/ROp32xMnqi3aqbTa6Pe\nk7FtwI6IGAKIiHuBe4BvAHcDe4Ch0StFxO0R0RoRrS0tLXUuyaYzT9RbNdPptVFL0Pcx8ix8ft5W\nSRtZoD8nIj4YEZdGxFWAgAdPpVCzU+GJeqtmOr02ahmj3wsskbSYLODbgHeM7iTpYuACsrP24bYm\nYHZEPC7pEuAS4N56FG5WC0/UWzXT6bUxbtBHxElJNwAdQBNwZ0QclHQL0BkR7XnXNmBbRERh9ZnA\n1yUBPAlcm0/MmjWMJ+qtmuny2tDIXC5fa2trdHZ2ll2GmdkZRdK+iGittGzKfalZ9+PdXHbXZWWX\nYWaWjCS+AsHMzKqbcmf0Sy9cyv3r7y+7DDOzM4quU9VlPqM3M0ucg97MLHEOejOzxDnozcwS56A3\nM0vclLvqxsxsutnV1TepX8XgoDczK1EjfgDFQzdmZiUa6wdQ6sVBb2ZWokb8AIqD3sysRI34ARQH\nvZk13K6uPlbeupvFm77Iylt3s6ur2m8Zpa8RP4DiyVgza6hGTD6eSRrxAygOejNrqLEmH6dj0MPk\n/wCKh27MrKEaMfloIznozayhGjH5aCM56M2soRox+WgjeYzezBqqEZOPNpKD3swabrInH20kD92Y\nmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mlriagl7Sakndknokbaqw/DZJ+/Pbg5IGCss+LOmg\npMOSPiZJ9dwBMzMb27jX0UtqArYCVwG9wF5J7RFxaLhPRNxY6L8BWJ7ffz2wErgkX/wA8Ebg/jrV\nb2Zm46jljH4F0BMRRyLiGWAbsGaM/uuAu/P7AZwNzALOAmYCPz71cs3MbKJqCfp5wNHC49687QUk\nLQQWA7sBImIPcB/waH7riIjDFda7XlKnpM7+/v6J7YGZmY2p3pOxbcCOiBgCkPRy4JXAfLI3h8sl\nvWH0ShFxe0S0RkRrS0tLnUsyM5veagn6PmBB4fH8vK2SNp4ftgF4G/DNiDgeEceBLwGvO5VCzczs\n1NQS9HuBJZIWS5pFFubtoztJuhi4ANhTaH4EeKOkGZJmkk3EvmDoxszMJs+4QR8RJ4EbgA6ykN4e\nEQcl3SLpmkLXNmBbREShbQfwA+AA8B3gOxHx+bpVb2Zm49LIXC5fa2trdHZ2ll2GmdkZRdK+iGit\ntMz/M9bMLHH+4RGzBtnV1edfVbJSOOjNGmBXVx+bdx5g8MQQAH0Dg2zeeQDAYW+TzkM3Zg2wpaP7\nuZAfNnhiiC0d3SVVZNOJg96sAY4NDE6o3ayeHPRmDTB3dvOE2s3qyUFv1gAbVy2leWbTiLbmmU1s\nXLW0pIpsOvFkrFkDDE+4+qobK4OD3qxB1i6f52C3UnjoxswscQ56M7PEOejNzBLnoDczS5yD3sws\ncQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDcz\nS5yD3swscQ56M7PE1RT0klZL6pbUI2lTheW3Sdqf3x6UNJC3v6nQvl/SzyStrfdOmJlZdeP+Zqyk\nJmArcBXQC+yV1B4Rh4b7RMSNhf4bgOV5+33ApXn7S4Ae4N567oCZmY2tljP6FUBPRByJiGeAbcCa\nMfqvA+6u0P6bwJci4umJl2lmZqeqlqCfBxwtPO7N215A0kJgMbC7wuI2Kr8BmJnZJKr3ZGwbsCMi\nhoqNkl4GvBroqLSSpOsldUrq7O/vr3NJZmbTWy1B3wcsKDyen7dVUu2s/e3Av0TEiUorRcTtEdEa\nEa0tLS01lGRmZrWqJej3AkskLZY0iyzM20d3knQxcAGwp8I2qo3bm5nZJBs36CPiJHAD2bDLYWB7\nRByUdIukawpd24BtERHF9SUtIvtE8NV6FW1mZrXTqFwuXWtra3R2dpZdhpnZGUXSvohorbTM/zPW\nzCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEueg\nNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q5\n6M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLXE1BL2m1pG5JPZI2VVh+m6T9+e1BSQOFZRdJ\nulfSYUmHJC2qX/lmZjaeGeN1kNQEbAWuAnqBvZLaI+LQcJ+IuLHQfwOwvLCJTwEfjIgvS3oR8Gy9\nijczs/HVcka/AuiJiCMR8QywDVgzRv91wN0AkpYBMyLiywARcTwinj7Nms3MbAJqCfp5wNHC4968\n7QUkLQQWA7vzplcAA5J2SuqStCX/hDB6vesldUrq7O/vn9gemJnZmOo9GdsG7IiIofzxDOANwB8B\nvwb8ErB+9EoRcXtEtEZEa0tLS51LMjOb3sYdowf6gAWFx/PztkragHcXHvcC+yPiCICkXcBrgb+f\neKlWq11dfWzp6ObYwCBzZzezcdVS1i6v+CHMzKaBWs7o9wJLJC2WNIsszNtHd5J0MXABsGfUurMl\nDZ+mXw4cGr2u1c+urj427zxA38AgAfQNDLJ55wF2dVV7bzaz1I0b9BFxErgB6AAOA9sj4qCkWyRd\nU+jaBmyLiCisO0Q2bPN/JR0ABNxRzx2wkbZ0dDN4YmhE2+CJIbZ0dJdUkZmVrZahGyLiHuCeUW0f\nGPX45irrfhm45BTrswk6NjA4oXYzS5//Z2xi5s5unlC7maXPQZ+YjauW0jxz5BWszTOb2LhqaUkV\nmVnZahq6sTPH8NU1vurGzIY56BO0dvk8B7uZPcdDN2ZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiVPh\nGwumBEn9wMOnsYk5wGN1KudM52Mxko/HSD4ez0vhWCyMiIpf/zvlgv50SeqMiNay65gKfCxG8vEY\nycfjeakfCw/dmJklzkFvZpa4FIP+9rILmEJ8LEby8RjJx+N5SR+L5MbozcxspBTP6M3MrMBBb2aW\nuGSCXtJqSd2SeiRtKrueMklaIOk+SYckHZT0h2XXVDZJTZK6JH2h7FrKJmm2pB2S/kPSYUmvK7um\nMkm6Mf938j1Jd0s6u+ya6i2JoJfUBGwF3gwsA9ZJWlZuVaU6CdwUEcuA1wLvnubHA+APyX7z2OCj\nwL9FxMXArzKNj4ukecAfAK0R8StAE9nvXycliaAHVgA9EXEkIp4BtgFrSq6pNBHxaER8O7//FNk/\n5Gn7BfWS5gNvAT5Zdi1lk3Q+8D+AvweIiGciYqDcqko3A2iWNAM4BzhWcj11l0rQzwOOFh73Mo2D\nrUjSImA58K1yKynVXwN/DDxbdiFTwGKgH/iHfCjrk5LOLbuoskREH/AR4BHgUeAnEXFvuVXVXypB\nbxVIehHwz8D/iogny66nDJLeCvxnROwru5YpYgbwGuDvImI58FNg2s5pSbqA7NP/YmAucK6ka8ut\nqv5SCfo+YEHh8fy8bdqSNJMs5D8bETvLrqdEK4FrJD1ENqR3uaTPlFtSqXqB3ogY/oS3gyz4p6sr\ngR9GRH9EnAB2Aq8vuaa6SyXo9wJLJC2WNItsMqW95JpKI0lkY7CHI+Kvyq6nTBGxOSLmR8QistfF\n7ohI7oytVhHxI+CopKV50xXAoRJLKtsjwGslnZP/u7mCBCenk/hx8Ig4KekGoINs1vzOiDhYclll\nWgm8EzggaX/e9r8j4p4Sa7KpYwPw2fyk6AhwXcn1lCYiviVpB/BtsqvVukjw6xD8FQhmZolLZejG\nzMyqcNCbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mlrj/D1yuX2fCbhl3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=pipe_log,\n",
    "                        X=Xtr_fin,\n",
    "                        y=ytr_fin,\n",
    "                        cv=10, \n",
    "                        n_jobs=1,\n",
    "                        scoring = 'roc_auc')\n",
    "\n",
    "print('Cross validation scores: {}'.format(scores))\n",
    "\n",
    "plt.title('Cross validation scores')\n",
    "plt.scatter(np.arange(len(scores)), scores)\n",
    "plt.axhline(y=np.mean(scores), color='g') # Mean value of cross validation scores\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However when we see the CV scores in this plot,there is quite a fluctuations based on 10 cvs. In this plot I am showing based on ROC-AUC scores, and still they are all more than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "zn4hBHdjRgr7",
    "outputId": "2069432d-dca7-4577-a2e2-6f73608a1f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.45283019 0.44393064 0.40049751 0.47820672 0.45454545 0.42758621\n",
      " 0.45601852 0.44893378 0.4452381  0.43396226]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKi4BH1ERMUl6CMiKu7/A9IL/M+vMm4hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=pipe_log,\n",
    "                        X=Xtr_fin,\n",
    "                        y=ytr_fin,\n",
    "                        cv=10, \n",
    "                        n_jobs=1,\n",
    "                        scoring = 'f1')\n",
    "\n",
    "print('Cross validation scores: {}'.format(scores))\n",
    "\n",
    "plt.title('Cross validation scores')\n",
    "plt.scatter(np.arange(len(scores)), scores)\n",
    "plt.axhline(y=np.mean(scores), color='g') # Mean value of cross validation scores\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I showed the CV scores based on F1 score --  most of them are above 0.40, which is quite good. But the scores are still fluctuating, indicating that actually there is still a room for improvement for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "FXAF-ppvRneD",
    "outputId": "e302a14c-572b-4eed-8cb6-29e3146de498"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-e9abd6f7270a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                        \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_try2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                        \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#generate 5 macem train size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                                        cv=10)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             error_score=error_score, return_times=return_times)\n\u001b[0;32m-> 1256\u001b[0;31m             for train, test in train_test_proportions)\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mn_cv_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mn_unique_ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    857\u001b[0m             class_weight_ = compute_class_weight(class_weight, mask_classes,\n\u001b[1;32m    858\u001b[0m                                                  y_bin)\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0msample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mclass_weight_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \"\"\"\n\u001b[1;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         return _encode_numpy(values, uniques, encode,\n\u001b[0;32m--> 118\u001b[0;31m                              check_unknown=check_unknown)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'quicksort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_log,\n",
    "                                                       X=logitsig2,\n",
    "                                                       y=target_try2,\n",
    "                                                       train_sizes=np.linspace(0.5, 1.0, 5), #generate 5 macem train size\n",
    "                                                       cv=10)\n",
    "\n",
    "print(train_scores)\n",
    "# Mean value of accuracy against training data\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "print('train mean')\n",
    "print(train_mean)\n",
    "print(\"train sizes\")\n",
    "print(train_sizes)\n",
    "\n",
    "# Standard deviation of training accuracy per number of training samples\n",
    "print('train std')\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "print(train_std)\n",
    "\n",
    "# Same as above for test data\n",
    "\n",
    "print('test mean')\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "print(test_mean)\n",
    "\n",
    "print('test std')\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "print(test_std)\n",
    "\n",
    "# Plot training accuracies \n",
    "plt.plot(train_sizes, train_mean, color='red', marker='o', label='Training Accuracy')\n",
    "# Plot the variance of training accuracies\n",
    "plt.fill_between(train_sizes,\n",
    "                train_mean + train_std,\n",
    "                train_mean - train_std,\n",
    "                alpha=0.15, color='red')\n",
    "\n",
    "# Plot for test data as training data\n",
    "plt.plot(train_sizes, test_mean, color='blue', linestyle='--', marker='s', \n",
    "        label='Test Accuracy')\n",
    "\n",
    "#fill between semacam std nya\n",
    "plt.fill_between(train_sizes,\n",
    "                test_mean + test_std,\n",
    "                test_mean - test_std,\n",
    "                alpha=0.15, color='blue')\n",
    "\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrkjIXXNdB1e"
   },
   "source": [
    "So far I have explored the model using all significant features -- it also helped me to know better which features are more important among the others (it's more for descriptive). \n",
    "\n",
    "But now supposed I want to predict just based on the characteristic of the customers : age, job, marital status, and education -- I did not put the housing and loan, because none of the them are significant in our earlier significance test. \n",
    "\n",
    "We will see whether our model earlier can help predict or at least give a probability whether customers with certain characteristic will be in our Target Yes or not.\n",
    "\n",
    "Now we will be back to our original dataset, and only taking the features I mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_m0UiZFZBQQ"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "solver = ['saga']\n",
    "max_iter = [1000, 1500, 2000, 3000]\n",
    "penalty = ['l1', 'l2']\n",
    "class_weight = [None, 'balanced']\n",
    "C = [0.01, 0.1, 1, 10,]\n",
    "\n",
    "log_reg_param = {'solver': solver,\n",
    "                 'max_iter': max_iter,\n",
    "                 'penalty': penalty,\n",
    "                 'class_weight': class_weight,\n",
    "                 'C': C}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "aMJhqf2Qem9g",
    "outputId": "aa89d107-71b4-4a96-bc9a-8264798b6675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      "age               41188 non-null int64\n",
      "job               41188 non-null object\n",
      "marital           41188 non-null object\n",
      "education         41188 non-null object\n",
      "default           41188 non-null object\n",
      "housing           41188 non-null object\n",
      "loan              41188 non-null object\n",
      "contact           41188 non-null object\n",
      "month             41188 non-null object\n",
      "day_of_week       41188 non-null object\n",
      "duration          41188 non-null int64\n",
      "campaign          41188 non-null int64\n",
      "pdays             41188 non-null int64\n",
      "previous          41188 non-null int64\n",
      "poutcome          41188 non-null object\n",
      "emp.var.rate      41188 non-null float64\n",
      "cons.price.idx    41188 non-null float64\n",
      "cons.conf.idx     41188 non-null float64\n",
      "euribor3m         41188 non-null float64\n",
      "nr.employed       41188 non-null float64\n",
      "y                 41188 non-null object\n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NpVUJ2Tgm8t"
   },
   "outputs": [],
   "source": [
    "bank_fin1 = bank[['job', 'marital', 'education', 'contact', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "1FtdYeL5g7nm",
    "outputId": "b2e77314-e24c-4b64-e33a-9051085da57a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>contact</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>telephone</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>telephone</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>telephone</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>telephone</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>telephone</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         job  marital    education    contact  age\n",
       "0  housemaid  married     basic.4y  telephone   56\n",
       "1   services  married  high.school  telephone   57\n",
       "2   services  married  high.school  telephone   37\n",
       "3     admin.  married     basic.6y  telephone   40\n",
       "4   services  married  high.school  telephone   56"
      ]
     },
     "execution_count": 183,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_fin1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9aLdG1b7g9w2"
   },
   "outputs": [],
   "source": [
    "fin1 = pd.get_dummies(bank_fin1, columns = bank_fin1.select_dtypes(exclude = 'number').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "zgQJHTyKhjB8",
    "outputId": "a5844e67-c523-421e-d952-99d313bffd34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "      <th>education_basic.4y</th>\n",
       "      <th>education_basic.6y</th>\n",
       "      <th>education_basic.9y</th>\n",
       "      <th>education_high.school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_professional.course</th>\n",
       "      <th>education_university.degree</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job_admin.  ...  contact_cellular  contact_telephone\n",
       "0   56           0  ...                 0                  1\n",
       "1   57           0  ...                 0                  1\n",
       "2   37           0  ...                 0                  1\n",
       "3   40           1  ...                 0                  1\n",
       "4   56           0  ...                 0                  1\n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqSw5Ro0hmOJ"
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(fin1, target, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "e1yNgE6ciPWv",
    "outputId": "7a34acdb-0c2a-4bc7-ab72-8bb259f5d45b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 187,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u3ai2FoOiS0q"
   },
   "outputs": [],
   "source": [
    "X_train2scale = scaler.fit_transform(X_train2)\n",
    "X_test2scale = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "4IBJVWVgic6Q",
    "outputId": "41824129-4324-439b-b37f-c5edc3ff38bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train2scale, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YN-u4uweihMG",
    "outputId": "d2bd30e7-eb0d-47b5-f507-bf96072ddf62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2737882577110873"
      ]
     },
     "execution_count": 192,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train2, log_reg.predict(X_train2scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oKAnxHgJjkkV",
    "outputId": "29fecda7-ef98-4fc5-d678-a56117e4ea60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2604960509907164"
      ]
     },
     "execution_count": 193,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test2, log_reg.predict(X_test2scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "KM5_769sjsad",
    "outputId": "89b1e2a9-6f40-47fa-cfcd-c01b627b19ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.55      0.69     10978\n",
      "           1       0.16      0.68      0.26      1379\n",
      "\n",
      "    accuracy                           0.57     12357\n",
      "   macro avg       0.55      0.62      0.48     12357\n",
      "weighted avg       0.85      0.57      0.65     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, log_reg.predict(X_test2scale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CzmVfQyUjyri",
    "outputId": "1bb42deb-f1be-48fb-814b-9e32ebb3bb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6080 4898]\n",
      " [ 439  940]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test2, log_reg.predict(X_test2scale)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQsdmK7Lj4NM"
   },
   "source": [
    "Our model surprisingly can predict more True positive than False Negative -- but False Positives is also increasing. Looking at full picture of our confusion matrix, it's actually indicating that our model is quite bad (probably because of lack of features) -- Almost 50% of Target No was miclassified (this can cost resources for bank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "bank-Supervised Learning PART 3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
